{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/home-data-for-ml-course/train.csv', index_col='Id')\nXtest = pd.read_csv('/kaggle/input/home-data-for-ml-course/test.csv', index_col='Id')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df.copy()\ny = X.pop('SalePrice')\n\nXtrain, Xvalid, y_train, y_valid = train_test_split(X, y, test_size=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nul_col = Xtrain.columns[Xtrain.isnull().sum()>0].tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Drop columns with more than half nulls","metadata":{}},{"cell_type":"code","source":"high_nul = Xtrain.columns[Xtrain.isnull().sum()> Xtrain.shape[0]/2].tolist()\n\nX_train = Xtrain.drop(high_nul, axis=1)\nX_valid = Xvalid.drop(high_nul, axis=1)\nX_test  = Xtest .drop(high_nul, axis=1)\n\nassert X_train.shape[1] == X_valid.shape[1] and X_train.shape[1] == X_test.shape[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Impute null values in numerical and categorical columns separately","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\nsi_num = SimpleImputer(strategy='mean')\nsi_obj = SimpleImputer(strategy='most_frequent')\n\nnum_cols = X_train.select_dtypes('number').columns.tolist()\nobj_cols = X_train.select_dtypes('object').columns.tolist()\n\nX_train[num_cols] = si_num.fit_transform(X_train[num_cols])\nX_train[obj_cols] = si_obj.fit_transform(X_train[obj_cols])\n\nX_valid[num_cols] = si_num.transform(X_valid[num_cols])\nX_valid[obj_cols] = si_obj.transform(X_valid[obj_cols])\n\nX_test[num_cols] = si_num.transform(X_test[num_cols])\nX_test[obj_cols] = si_obj.transform(X_test[obj_cols])\n\nassert X_train.isnull().sum().sum() == 0\nassert X_valid.isnull().sum().sum() == 0\nassert X_test.isnull().sum().sum() == 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Drop categorical columns with more than 10 unique values","metadata":{}},{"cell_type":"code","source":"high_unq = X_train[obj_cols].columns[X_train[obj_cols].nunique()>10].tolist()\n\nX_train.drop(high_unq, axis=1, inplace=True)\nX_valid.drop(high_unq, axis=1, inplace=True)\nX_test.drop(high_unq, axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Converting categorical data types into One-Hot","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\ncat_col = X_train.select_dtypes('object').columns.tolist()\nnum_col = X_train.select_dtypes('number').columns.tolist()\n\nohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n\nX_train_oh = pd.DataFrame(ohe.fit_transform(X_train[cat_col]))\nX_valid_oh = pd.DataFrame(ohe.transform(X_valid[cat_col]))\nX_test_oh =  pd.DataFrame(ohe.transform(X_test[cat_col]))\n\nX_train_oh.index = X_train.index\nX_valid_oh.index = X_valid.index\nX_test_oh .index = X_test .index\n\nX1_train = pd.concat([X_train[num_col], X_train_oh], axis=1)\nX1_valid = pd.concat([X_valid[num_col], X_valid_oh], axis=1)\nX1_test  = pd.concat([X_test[num_col] , X_test_oh ], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Remove any left over categorical columns\nin case that one-hot encoder is not used","metadata":{}},{"cell_type":"code","source":"cat_col = X1_train.select_dtypes('object').columns.tolist()\nprint(cat_col)\n\nX1_train.drop(cat_col, axis=1, inplace=True)\nX1_valid.drop(cat_col, axis=1, inplace=True)\nX1_test.drop(cat_col, axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 1: Decision Tree","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ndt_model = DecisionTreeRegressor()\n\ndt_model.fit(X1_train, y_train)\ny_val_pred = dt_model.predict(X1_valid)\ny_tst_pred = dt_model.predict(X1_test)\n\nval_error = abs(y_val_pred - y_valid).mean()\nprint(val_error)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 2: Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nrfr_model = RandomForestRegressor()\n\nrfr_model.fit(X1_train, y_train)\ny2_val_pred = rfr_model.predict(X1_valid)\ny2_tst_pred = rfr_model.predict(X1_test)\n\nval2_error = abs(y2_val_pred - y_valid).mean()\nprint(val2_error)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 3: Random Forest with defined parameters","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nrfr_model = RandomForestRegressor(n_estimators=500, criterion='mae', max_depth=500, min_samples_leaf=2)\n\nrfr_model.fit(X1_train, y_train)\ny3_val_pred = rfr_model.predict(X1_valid)\ny3_tst_pred = rfr_model.predict(X1_test)\n\nval3_error = abs(y3_val_pred - y_valid).mean()\nprint(val3_error)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y3_trn_pred = rfr_model.predict(X1_train)\ntrn3_error = abs(y3_trn_pred - y_train).mean()\nprint(trn3_error)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}